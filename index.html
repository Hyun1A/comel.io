<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis">
  <meta name="keywords" content="Multiple instance learning, Continual learning, Histopathology WSI, Localization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']] // 인라인 수식 정의
            }
        };
    </script>
  
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis
          </h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hyun1a.github.io/">Byung Hyun Lee</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ignoww.github.io/">Wongi Jeong</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://icl.snu.ac.kr/members#h.8qdjmhuhhfmc">Woojae Han</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="http://www.snuh.org/global/en/blog/01197/career.do">Kyoungbun Lee</a><sup>4</sup>,</span>
            <span class="https://icl.snu.ac.kr/members#h.vtqn6t6r1xdc">
              <a href="https://icl.snu.ac.kr/pi">Se Young Chun</a><sup>1</sup><sup>,</sup><sup>2</sup><sup>,</sup><sup>3</sup><sup>,</sup><sup>&#8224</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of ECE, <sup>2</sup>IPAI, <sup>3</sup>INMC, Seoul National University</span>
          </div>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>4</sup>Department of Pathology, College of Medicine, Seoul National University</span>
          </div>
          
          <div class="is-size-10 publication-authors">
            <span class="author-block">&#8224 Corresponding author</span>
          </div>
          <h3 class="title is-5 publication-title" style="margin-top: 1rem;">
            Accepted at ICCV 2025
          </h3>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2507.02395"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Hyun1A/CoMEL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multiple instance learning (MIL) significantly reduced annotation costs via bag-level weak labels for large-scale images, 
            such as histopathological whole slide images (WSIs). 
            However, its adaptability to continual tasks with minimal forgetting has been rarely explored, 
            especially on instance classification for localization. 
            Weakly incremental learning for semantic segmentation has been studied for continual localization, 
            but it focused on natural images, leveraging global relationships among hundreds of small patches (e.g., $16 \times 16$) using pre-trained models. 
            This approach seems infeasible for MIL localization due to enormous amounts ($\sim 10^5$) of large patches (e.g., $256 \times 256$) 
            and no available global relationships such as cancer cells. 
            To address these challenges, we propose Continual Multiple Instance Learning with Enhanced Localization (CoMEL), 
            an MIL framework  for both localization and adaptability with minimal forgetting. 
            CoMEL consists of (1) Grouped Double Attention Transformer (GDAT) for efficient instance encoding, 
            (2) Bag Prototypes-based Pseudo-Labeling (BPPL) for reliable instance pseudo-labeling, 
            and (3) Orthogonal Weighted Low-Rank Adaptation (OWLoRA) to mitigate forgetting in both bag and instance classification. 
            Extensive experiments on three public WSI datasets demonstrate superior performance of CoMEL, 
            outperforming the prior arts by up to $11.00\%$ in bag-level accuracy and up to $23.4\%$ in localization accuracy under the continual MIL setup.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>



  

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Illustration of Continual Multiple instance learning with Enhanced Localization (CoMEL)</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="900" height="450"
                      src="./static/figures_comel/figure1.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  In this work, we propose Continual Multiple instance learning with Enhanced Localization (CoMEL). 
                  Compared to the baseline (ConSlide), 
                  it alleviates forgetting of localization under multiple instance learning while effectively learning new task.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview of Method Components in CoMEL</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="900" height="450"
                      src="./static/figures_comel/figure2.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  Overview of Continual Multiple instance learning with Enhanced Localization (CoMEL). 
                  It aims to alleviate the forgetting of both bag and instance classification on previous tasks under the MIL setup, 
                  while effectively learning new tasks. It consists of three key components: 
                  Grouped Double Attention Transformer (GDAT), 
                  Bag Prototypes-based Pseudo-Labeling (BPPL), 
                  and Orthogonal Weighted Low-Rank Adapatation (OWLoRA).
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Grouped Double Attention Transformer (GDAT) and Bag Prototypes-based Pseudo-Labeling (BPPL)</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="1200" height="600"
                      src="./static/figures_comel/figure3.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  Components of (a) Grouped Double Attention Transformer (GDAT) and 
                  (b) Bag Prototypes-based Pseudo-Labeling (BPPL) for enhanced localization. 
                  GDAT utilizes two sequential efficient attention with small number of grouped tokens 
                  by averaging instances in same region into one token. 
                  For BPPL, we normalize the attention as predicted class probability
                  and obtain both positive and negative prototypes for pseudo-labeling, 
                  and then filter the pseudo-labels via the performance of bag and instance classification.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>


  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Orthogonal Weighted Low-Rank Adaptation (OWLoRA)</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="600" height="300"
                      src="./static/figures_comel/figure4.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  Illustration of Orthogonal Weighted Low-Rank Adaptation (OWLoRA) for continual MIL. For orthogonality of 1st task, 
                  OWLoRA trains the full-rank weights and then extracts principal orthogonal components by singular value decomposition.
                  For subsequent tasks, it imposes the intra- and inter-orthogonality on the bases for low-rank learnable matrices for the current task.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative Results on Continual Instance Classification in MIL</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="1200" height="600"
                      src="./static/figures_comel/table1.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  Quantitative results of CL methods on instance classification in the continual MIL setup. 
                  The best and second best results are marked as bold and underline. 
                  Each experiment consisted of 10 runs. 
                  We conducted the experiments on five sequential organ datasets from combined CM-16 and PAIP. 
                  For baselines, we applied the CL approaches upon our GDAT+BPPL, except for ConSlide. 
                  All metrics were measured in percentage. 
                  CoMEL achieved the highest performance across all metrics while minimizing the forgetting.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>



  




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Illustration of Continual Instance Classification over Tasks</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="900" height="450"
                      src="./static/figures_comel/figure5.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                   Instance-level classification accuracy over sequentially learned organs from combined CM-16 and PAIP. 
                  Each figure shows the forgetting for a specific organ under continual MIL setup. 
                  Task Index indicates the order of organs in the sequential tasks. 
                  CoMEL consistently achieved superior performance across all tasks, effectively mitigating catastrophic forgetting.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>



  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results on Continual Instance Classification in MIL</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="1200" height="600"
                      src="./static/figures_comel/figure6.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                   Qualitative results of localization across sequential organ datasets under continual MIL setup. 
                  Each column shows localization performance on Task 1 (left) or 2 (right) 
                  as the learned organ changes over sequential tasks. 
                  Each row corresponds to CL methods including CoMEL. 
                  CoMEL successfully preserved the localization quality across all tasks, 
                  while baselines increase false positives or false negatives.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>
  

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Additional Qualitative Results - 1</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="1200" height="600"
                      src="./static/figures_comel/figure7.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                  Additional qualitative results of localization across sequential organ datasets under the continual MIL setup. 
                  Each column is the localization performance on Task 1 as the learned organ changes over sequential tasks. 
                  Each row corresponds to CL methods including CoMEL. 
                  CoMEL successfully preserved the localization quality across all tasks, 
                  while baselines increase false positives or false negatives.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>










<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Additional Qualitative Results - 2</h2>
          <div className="container is-max-desktop">
              <img id="overview"
                       width="1200" height="600"
                      src="./static/figures_comel/figure8.png"
                      alt={"overview"}>
              </img>

              <div class="content has-text-justified"> 
                <p>
                   Additional qualitative results of localization across sequential organ datasets under the continual MIL setup. 
                  Each column is the localization performance on Task 2 as the learned organ changes over sequential tasks. 
                  Each row corresponds to CL methods including CoMEL. 
                  CoMEL successfully preserved the localization quality across all tasks, 
                  while baselines increase false positives or false negatives.
                </p>
              </div>
          </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{lee2025gloce,
          author    = {Lee, Byung Hyun and Jeong, Wongi and Han, Woojae and Lee, Kyoungbun and Chun, Se Young},
          title     = {Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis},
          booktitle = {ICCV}
          year      = {2025},
      }</code></pre>
  </div>
</section>

  
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
